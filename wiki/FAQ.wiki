#summary Frequently asked questions
#labels Featured

<wiki:toc max_depth="4" />


= Introduction =

This is a list of questions that might be frequently asked.  It will be extended as more questions come to light.

= Questions =

== I have a question about how to use the software ==

Contact the developer, or join the Biodiverse-Users google group and post a question there.  

== I have found a bug ==

Please submit bugs via the Issues list at http://code.google.com/p/biodiverse/issues/list

== I would like a new feature to be added to Biodiverse ==

These are also submitted via the issues list.  Just specify the type label as Type-Enhancement (click on the _Type-Defect_ box to open the menu containing this option).  http://code.google.com/p/biodiverse/issues/list

== My species list has been provided as a site by species matrix.  How do I import it? ==

Turn on the checkbox next to _Data are in matrix form?_ when importing.  See [SampleSession#BaseData].

== Can I skip a subset of species when importing data? ==

Yes.  Use an Element Property table for this purpose, specifying one or more exclude and/or include columns.  See [DataStructures#Element_property_tables].

== Results exported to ER-Mapper BIL files do not display properly in !ArcMap ==

You will need to calculate statistics for the image for it to display properly.  This can be done in ArcCatalog by right clicking on the file and choosing Calculate Statistics, or by using the _Calculate Statistics_ tool in ArcToolbox.

== Out of memory error ==

In some cases the system will use up all the available memory, following which it will crash.  Specific cases are the randomisations (see issue #20) and when one is using a large !BaseData object (e.g. >100,000 groups and ~60 labels) and tries to save the data set while displaying several outputs.

The cause is that Biodiverse is implemented in Perl, and therefore uses its memory management system (this makes development much easier).  However, on 32 bit systems the maximum memory allocated to a process is 2GB.  If more than this is needed then the system will crash.  There is also the issue that Perl's memory management system is not perfect, and does not free all memory in case it might need it again later.  This particularly affects the randomisations, as each iteration is assigned a chunk of memory that is not returned to the general pool.  Eventually the system runs out of available memory.

The solution for the large data sets is to close any open tabs before exporting or saving, as the memory used for display is freed and returned properly.  If it still does not work then the only reasonable solution is to move to a 64 bit system which allows more memory per process.  make sure Perl and GTK are both 64 bit, as 32 bit implementations still have the 2GB memory limitation on these systems.

An alternate solution, if a 64 bit system is not available, is to subdivide the !BaseData object into tiles before analysis, although cluster analyses are then not possible.  One must also include overlapping boundaries to ensure moving window analyses have the correct neighbour sets.  Indices that use global statistics, such as when endemism sues the global range, need to also be adjusted.  Global ranges and global sample counts can be set using an Element Properties table.  The range and sample count values can be calculated using endemism and rarity analyses with a spatial condition set to `sp_select_all()`, and then extracted by control clicking on the displayed results to see the lists, from which the values can be copied into a spreadsheet or other program.  (This assumes you can display the results - if not then a script is the only way to go).